{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ec627e5-8b8d-4c76-bc2c-519af5b32d20",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "In this tutorial, we will perform multi-label classification using an ECG-FM model finetuned on the [MIMIC-IV-ECG v1.0 dataset](https://physionet.org/content/mimic-iv-ecg/1.0/). It outlines the data and model loading, as well as inference, same-sample prediction aggregation, and visualizations for embeddings and saliency maps.\n",
    "\n",
    "ECG-FM was developed in collaboration with the [fairseq_signals](https://github.com/Jwoo5/fairseq-signals) framework, which implements a collection of deep learning methods for ECG analysis.\n",
    "\n",
    "This is segment the ECG into inputs of 5 s and perform a label-specific aggregation of the predictions from each sample\n",
    "\n",
    "This document serves largely as a quickstart introduction. Much of this functionality is also available via the [fairseq-signals scripts](https://github.com/bowang-lab/ECG-FM/blob/main/notebooks/infer_cli.ipynb), as well the [ECG-FM scripts](https://github.com/bowang-lab/ECG-FM/tree/main/scripts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a9804-4444-4aaa-af00-8c9869cbcc5a",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Begin by cloning [fairseq_signals](https://github.com/Jwoo5/fairseq-signals) and refer to the installation section in the top-level README. For example, the following commands are sufficient at the present moment:\n",
    "```\n",
    "# Creating `fairseq` environment:\n",
    "conda create --name fairseq python=3.10.6\n",
    "source activate fairseq\n",
    "git clone https://github.com/Jwoo5/fairseq-signals\n",
    "cd fairseq-signals\n",
    "python3 -m pip install pip==24.0\n",
    "python3 -m pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5992565-e416-4103-a0e7-e2b8a09893f8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# You may require the following imports depending on what functionality you run\n",
    "!pip install huggingface-hub\n",
    "!pip install pandas\n",
    "!pip install ecg-transform==0.1.3\n",
    "!pip install umap-learn\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f34c08a-bb4c-4182-a604-e4bc0db0e46b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T16:33:46.618513900Z",
     "start_time": "2025-08-06T16:33:46.615615900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec114e98-ad66-46c3-875f-088a8786781e",
   "metadata": {},
   "source": [
    "## Download checkpoints\n",
    "\n",
    "Checkpoints are available on [HuggingFace](https://huggingface.co/wanglab/ecg-fm). The finetuned model be downloaded using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614f439f-5825-4614-a105-39353c36b5cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T16:33:47.159242300Z",
     "start_time": "2025-08-06T16:33:46.619514500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "_ = hf_hub_download(\n",
    "    repo_id='wanglab/ecg-fm',\n",
    "    filename='mimic_iv_ecg_finetuned.yaml',\n",
    "    local_dir=os.path.join(root, 'ckpts'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bbab44-7039-475c-8868-ad2396b5c858",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import chain\n",
    "from typing import List, Dict\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, matthews_corrcoef\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ECG-FM imports\n",
    "from ecg_transform.inp import ECGInput, ECGInputSchema\n",
    "from ecg_transform.sample import ECGSample, ECGMetadata\n",
    "from ecg_transform.t.base import ECGTransform\n",
    "from ecg_transform.t.common import (\n",
    "    HandleConstantLeads,\n",
    "    LinearResample,\n",
    "    ReorderLeads,\n",
    ")\n",
    "from ecg_transform.t.scale import Standardize\n",
    "from ecg_transform.t.cut import SegmentNonoverlapping\n",
    "\n",
    "from fairseq_signals.models import build_model_from_checkpoint\n",
    "from fairseq_signals.models.classification.ecg_transformer_classifier import ECGTransformerClassificationModel\n",
    "\n",
    "# -----------------------------\n",
    "# Constants\n",
    "# -----------------------------\n",
    "ECG_FM_LEAD_ORDER = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "SAMPLE_RATE = 500\n",
    "N_SAMPLES = SAMPLE_RATE * 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load Data (Change dataset path for other downstream tasks)\n",
    "# -----------------------------\n",
    "lead_file_paths = {\n",
    "    f\"LEAD_{lead}\": f\"data_aspire_PAP/LEAD_{lead}.pt\" for lead in ECG_FM_LEAD_ORDER\n",
    "}\n",
    "labels_file_path = \"data_aspire_PAP/labels.pt\"\n",
    "\n",
    "ecg_lead_tensors = {lead: torch.load(path) for lead, path in lead_file_paths.items()}\n",
    "labels = torch.load(labels_file_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Schema and Transforms\n",
    "# -----------------------------\n",
    "ECG_FM_SCHEMA = ECGInputSchema(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    expected_lead_order=ECG_FM_LEAD_ORDER,\n",
    "    required_num_samples=N_SAMPLES,\n",
    ")\n",
    "\n",
    "ECG_FM_TRANSFORMS = [\n",
    "    ReorderLeads(expected_order=ECG_FM_LEAD_ORDER, missing_lead_strategy='raise'),\n",
    "    LinearResample(desired_sample_rate=SAMPLE_RATE),\n",
    "    HandleConstantLeads(strategy='zero'),\n",
    "    Standardize(),\n",
    "    SegmentNonoverlapping(segment_length=N_SAMPLES),\n",
    "]\n",
    "\n",
    "class ECGFromPTDataset(Dataset):\n",
    "    def __init__(self, ecg_leads_dict, labels, schema, transforms):\n",
    "        self.ecg_leads = ecg_leads_dict\n",
    "        self.labels = labels\n",
    "        self.schema = schema\n",
    "        self.transforms = transforms\n",
    "        self.lead_names = list(ecg_leads_dict.keys())\n",
    "        self.num_samples = len(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.stack([self.ecg_leads[lead][idx].numpy() for lead in self.lead_names], axis=0)\n",
    "        metadata = ECGMetadata(\n",
    "            sample_rate=SAMPLE_RATE,\n",
    "            num_samples=data.shape[1],\n",
    "            lead_names=[lead.replace(\"LEAD_\", \"\") for lead in self.lead_names],\n",
    "            input_start=0,\n",
    "            input_end=data.shape[1],\n",
    "            unit=None\n",
    "        )\n",
    "        metadata.file = f\"sample_{idx}\"\n",
    "\n",
    "        inp = ECGInput(data, metadata)\n",
    "        sample = ECGSample(inp, self.schema, self.transforms)\n",
    "        source = torch.from_numpy(sample.out).float()\n",
    "        return {\"source\": source, \"label\": self.labels[idx]}\n",
    "\n",
    "def collate_fn(samples: List[Dict]):\n",
    "    x_segments = [s[\"source\"] for s in samples]  # list of [segments, C]\n",
    "    x_lens = [seg.shape[0] for seg in x_segments]\n",
    "    x = torch.cat(x_segments, dim=0)  # [total_segments, C]\n",
    "    y = torch.tensor([s[\"label\"] for s in samples])  # [B]\n",
    "    y = torch.repeat_interleave(y, torch.tensor(x_lens))  # repeat each label per segment\n",
    "    return {\"net_input\": {\"source\": x}, \"label\": y}\n",
    "\n",
    "def pt_data_loader(dataset, batch_size=64, num_workers=0):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn)\n",
    "\n",
    "# -----------------------------\n",
    "# Load Pretrained ECG-FM Model\n",
    "# -----------------------------\n",
    "ckpt_path = \"mimic_iv_ecg_physionet_pretrained.pt\"\n",
    "model: ECGTransformerClassificationModel = build_model_from_checkpoint(checkpoint_path=ckpt_path)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# Training and Evaluation\n",
    "# -----------------------------\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        x = batch[\"net_input\"][\"source\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_dict = model(source=x)\n",
    "        logits = model.get_logits(output_dict)\n",
    "        if logits.shape[0] != y.shape[0]:\n",
    "            min_len = min(logits.shape[0], y.shape[0])\n",
    "            logits = logits[:min_len]\n",
    "            y = y[:min_len]\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x = batch[\"net_input\"][\"source\"].to(device)\n",
    "            y = batch[\"label\"].to(device)\n",
    "            output_dict = model(source=x)\n",
    "            logits = model.get_logits(output_dict)\n",
    "            prob = torch.softmax(logits, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            min_len = min(len(y), len(pred))\n",
    "            y, pred, prob = y[:min_len], pred[:min_len], prob[:min_len]\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_probs.extend(prob[:, 1].cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    return acc, auc, f1, mcc\n",
    "\n",
    "# -----------------------------\n",
    "# K-Fold Cross Validation\n",
    "# -----------------------------\n",
    "dataset = ECGFromPTDataset(ecg_lead_tensors, labels, ECG_FM_SCHEMA, ECG_FM_TRANSFORMS)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "    print(f\"FOLD {fold}\")\n",
    "    train_loader = pt_data_loader(Subset(dataset, train_idx), batch_size=64)\n",
    "    test_loader = pt_data_loader(Subset(dataset, test_idx), batch_size=64)\n",
    "\n",
    "    clf = build_model_from_checkpoint(checkpoint_path=ckpt_path)\n",
    "    clf.eval()\n",
    "    clf.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(clf.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        loss = train_one_epoch(clf, train_loader, criterion, optimizer)\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss:.4f}\")\n",
    "\n",
    "    acc, auc, f1, mcc = evaluate(clf, test_loader)\n",
    "    fold_results.append((acc, auc, f1, mcc))\n",
    "    print(f\"Fold {fold} Results: Acc={acc:.4f}, AUC={auc:.4f}, F1={f1:.4f}, MCC={mcc:.4f}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Results Summary\n",
    "# -----------------------------\n",
    "accuracies, aucs, f1s, mccs = zip(*fold_results)\n",
    "print(f'Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}')\n",
    "print(f'Mean AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}')\n",
    "print(f'Mean F1: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}')\n",
    "print(f'Mean MCC: {np.mean(mccs):.4f} ± {np.std(mccs):.4f}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8902655580ecdd9e",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
